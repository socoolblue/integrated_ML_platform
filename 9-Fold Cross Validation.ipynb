{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    regr = LinearRegression(n_jobs=-1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred) \n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#Basic Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    ridge_reg=Ridge(random_state=0,alpha=0.5)\n",
    "    ridge_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=ridge_reg.predict(x_data_training)\n",
    "    y_pred=ridge_reg.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred) \n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    lasso_reg=linear_model.Lasso(random_state=0,alpha=0.001)\n",
    "    lasso_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=lasso_reg.predict(x_data_training)\n",
    "    y_pred=lasso_reg.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    regr = linear_model.LassoLars(alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    regr = ElasticNet(random_state=0,l1_ratio=0.7, alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#ENR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(nu=2.5,length_scale=100)\n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    KRR_regr = KernelRidge(kernel='sigmoid', alpha=0.01,coef0=1)\n",
    "    KRR_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=KRR_regr.predict(x_data_training)\n",
    "    y_pred=KRR_regr.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    Bay_Reg = linear_model.BayesianRidge(tol=0.00001)\n",
    "    Bay_Reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr =Bay_Reg.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_ = Bay_Reg.predict(x_data_validation, return_std=True)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[0:8],train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.scatter(train[0:8], stdPtr[0:8])\n",
    "plt.scatter(train[0:8], stdMtr[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()        \n",
    "\n",
    "plt.plot(validation[0:8],validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.scatter(validation[0:8], stdP[0:8])\n",
    "plt.scatter(validation[0:8], stdM[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#BRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    regr = linear_model.ARDRegression(alpha_1=1e-08,alpha_2=1e-04,lambda_1=1e-04,lambda_2=1e-06)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr=regr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=regr.predict(x_data_validation,return_std=True)    \n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[0:8],train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.scatter(train[0:8], stdPtr[0:8])\n",
    "plt.scatter(train[0:8], stdMtr[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()        \n",
    "\n",
    "plt.plot(validation[0:8],validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.scatter(validation[0:8], stdP[0:8])\n",
    "plt.scatter(validation[0:8], stdM[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    forest_reg = RandomForestRegressor(max_features='sqrt', random_state=0, n_estimators=100, max_depth=10)\n",
    "    forest_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=forest_reg.predict(x_data_training)\n",
    "    y_pred=forest_reg.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "    \n",
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    Ada_regr = AdaBoostRegressor(random_state=0, loss='square',learning_rate=0.01, n_estimators=50)\n",
    "    Ada_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=Ada_regr.predict(x_data_training)\n",
    "    y_pred=Ada_regr.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "    \n",
    "#Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "        \n",
    "    gradientboost_reg = GradientBoostingRegressor(loss='lad', learning_rate=0.1, n_estimators=100, subsample=0.7, random_state=0)\n",
    "    gradientboost_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=gradientboost_reg.predict(x_data_training)\n",
    "    y_pred=gradientboost_reg.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)                          \n",
    "                                                                   \n",
    "#Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "    \n",
    "    xg_reg = xgb.XGBRegressor(learning_rate=0.1,subsample=0.4, max_depth=4, random_state=0)\n",
    "    xg_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=xg_reg.predict(x_data_training)\n",
    "    y_pred=xg_reg.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=1.0, nu=2.5)\n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "       \n",
    "    svr_reg = SVR(kernel='linear', C=1)\n",
    "    svr_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=svr_reg.predict(x_data_training)\n",
    "    y_pred=svr_reg.predict(x_data_validation)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    knn_reg = KNeighborsRegressor(weights='distance', n_neighbors= 3, p=1, )\n",
    "    knn_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=knn_reg.predict(x_data_training)\n",
    "    y_pred=knn_reg.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "        \n",
    "    regr = PLSRegression(n_components=1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_validation)\n",
    "    \n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=10.0, nu=0.5) \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "validation = []\n",
    "train_p = []\n",
    "validation_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "groups=np.full((len(xy)),8)\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "    groups[i*cut_data:(i*cut_data)+cut_data]=i\n",
    "    \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)  \n",
    "\n",
    "for train_index, validation_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_validation = x_data[train_index], x_data[validation_index]\n",
    "    y_data_training, y_data_validation = y_data[train_index], y_data[validation_index]\n",
    "\n",
    "    gpr = GaussianProcessRegressor(random_state=0, alpha=1e-10, kernel= kernel)\n",
    "    gpr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr=gpr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=gpr.predict(x_data_validation, return_std=True)    \n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_validation, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_validation, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    validation.append(y_data_validation)\n",
    "    train_p.append(y_pred_tr)\n",
    "    validation_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation[0:8], validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[0:8],train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.scatter(train[0:8], stdPtr[0:8])\n",
    "plt.scatter(train[0:8], stdMtr[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()        \n",
    "\n",
    "plt.plot(validation[0:8],validation[0:8])\n",
    "plt.scatter(validation[0:8], validation_p[0:8])\n",
    "plt.scatter(validation[0:8], stdP[0:8])\n",
    "plt.scatter(validation[0:8], stdM[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/9,r2_tr/9,MSE_val/9,r2_val/9)\n",
    "\n",
    "#GPR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
