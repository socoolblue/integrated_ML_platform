{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "    regr = LinearRegression(n_jobs=-1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')\n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#Basic Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    ridge_reg=Ridge(random_state=0,alpha=0.5)\n",
    "    ridge_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=ridge_reg.predict(x_data_training)\n",
    "    y_pred=ridge_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=ridge_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    lasso_reg=linear_model.Lasso(random_state=0,alpha=0.001)\n",
    "    lasso_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=lasso_reg.predict(x_data_training)\n",
    "    y_pred=lasso_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=lasso_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    regr = linear_model.LassoLars(alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    regr = ElasticNet(random_state=0, l1_ratio= 0.7, alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#ENR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "    \n",
    "    KRR_regr = KernelRidge(kernel='sigmoid', alpha=0.01,coef0=1)\n",
    "    KRR_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=KRR_regr.predict(x_data_training)\n",
    "    y_pred=KRR_regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=KRR_regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    Bay_Reg = linear_model.BayesianRidge(tol=0.00001)\n",
    "    Bay_Reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr=Bay_Reg.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_ = Bay_Reg.predict(x_data_val, return_std=True)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "\n",
    "y_pred_, std_te=Bay_Reg.predict(x_data_test_, return_std=True)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "std_P_te =  y_pred_ + std_te\n",
    "std_M_te =  y_pred_ - std_te\n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#BRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    regr = linear_model.ARDRegression(alpha_1=1e-08, alpha_2=1e-04, lambda_1=1e-04, lambda_2=1e-06)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr,std_tr=regr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=regr.predict(x_data_val,return_std=True)  \n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "\n",
    "y_pred_, std_te=regr.predict(x_data_test_,return_std=True)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "std_P_te =  y_pred_ + std_te\n",
    "std_M_te =  y_pred_ - std_te\n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    forest_reg = RandomForestRegressor(random_state=0, max_features='sqrt', n_estimators=100, max_depth=10)\n",
    "    forest_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=forest_reg.predict(x_data_training)\n",
    "    y_pred=forest_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=forest_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)  \n",
    "    \n",
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    Ada_regr = AdaBoostRegressor(random_state=0, loss='square',learning_rate=0.01, n_estimators=50)\n",
    "    Ada_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=Ada_regr.predict(x_data_training)\n",
    "    y_pred=Ada_regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=Ada_regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    gradientboost_reg = GradientBoostingRegressor(subsample=0.7, loss='lad',learning_rate=0.1, n_estimators=100, random_state=0)\n",
    "    gradientboost_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=gradientboost_reg.predict(x_data_training)\n",
    "    y_pred=gradientboost_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=gradientboost_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)                               \n",
    "                                         \n",
    "#Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    xg_reg = xgb.XGBRegressor(subsample=0.4,learning_rate=0.1, max_depth=4, random_state=0, seed=0)\n",
    "    xg_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=xg_reg.predict(x_data_training)\n",
    "    y_pred=xg_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=xg_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "    \n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=1.0, nu=2.5)\n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    svr_reg = SVR(kernel='linear', C=1)\n",
    "    svr_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=svr_reg.predict(x_data_training)\n",
    "    y_pred=svr_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=svr_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    knn_reg = KNeighborsRegressor(n_neighbors= 3,  weights='distance', p=1)\n",
    "    knn_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=knn_reg.predict(x_data_training)\n",
    "    y_pred=knn_reg.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=knn_reg.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n"
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    regr = PLSRegression(n_components=1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_val)\n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "\n",
    "y_pred_=regr.predict(x_data_test_)\n",
    "r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')\n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=10.0, nu=0.5) \n",
    "\n",
    "r2_tr=0\n",
    "r2_val=0\n",
    "MSE_tr=0\n",
    "MSE_val=0\n",
    "train = []\n",
    "val = []\n",
    "train_p = []\n",
    "val_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "np.random.shuffle(xy_data)\n",
    "x_data = xy_data[11:, :-2]\n",
    "y_data = xy_data[11:, -2]\n",
    "x_data_test_= xy_data[:11, :-2]\n",
    "y_data_test_= xy_data[:11, -2]    \n",
    "\n",
    "groups = np.zeros((len(x_data)))\n",
    "cut_data=10\n",
    "for i in range(int(len(groups)/cut_data)):\n",
    "        groups[i*cut_data:(i*cut_data)+10]=i\n",
    "        \n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_data, y_data, groups)\n",
    "\n",
    "logo.get_n_splits(groups=groups)\n",
    "\n",
    "for train_index, val_index in logo.split(x_data, y_data, groups):\n",
    "\n",
    "    x_data_training, x_data_val = x_data[train_index], x_data[val_index]\n",
    "    y_data_training, y_data_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "    gpr = GaussianProcessRegressor(random_state=0, alpha=1e-10, kernel=kernel)\n",
    "    gpr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr=gpr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=gpr.predict(x_data_val, return_std=True) \n",
    "\n",
    "    r2_tr+=r2_score(y_data_training, y_pred_tr, multioutput='variance_weighted')\n",
    "    r2_val+=r2_score(y_data_val, y_pred, multioutput='variance_weighted')\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_val+=mean_squared_error(y_data_val, y_pred, multioutput='uniform_average')\n",
    "\n",
    "    train.append(y_data_training)\n",
    "    val.append(y_data_val)\n",
    "    train_p.append(y_pred_tr)\n",
    "    val_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "        \n",
    "    y_pred_, std_te=gpr.predict(x_data_test_, return_std=True)\n",
    "    r2_te_=r2_score(y_data_test_, y_pred_, multioutput='variance_weighted')\n",
    "    MSE_te_=mean_squared_error(y_data_test_, y_pred_, multioutput='uniform_average')  \n",
    "    std_P_te =  y_pred_ + std_te\n",
    "    std_M_te =  y_pred_ - std_te \n",
    "\n",
    "plt.plot(train[0:8], train[0:8])\n",
    "plt.scatter(train[0:8], train_p[0:8])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/8,r2_tr/8,MSE_val/8,r2_val/8,MSE_te_,r2_te_)\n",
    "\n",
    "#GPR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
