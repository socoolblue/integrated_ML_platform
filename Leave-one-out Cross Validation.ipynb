{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    regr = LinearRegression(n_jobs=-1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)\n",
    "\n",
    "#Basic Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    ridge_reg=Ridge(random_state=0,alpha=0.5)\n",
    "    ridge_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=ridge_reg.predict(x_data_training)\n",
    "    y_pred=ridge_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    lasso_reg=linear_model.Lasso(random_state=0,alpha=0.001)\n",
    "    lasso_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=lasso_reg.predict(x_data_training)\n",
    "    y_pred=lasso_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)\n",
    "\n",
    "#Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    regr = linear_model.LassoLars(alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)\n",
    "\n",
    "#LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    regr = ElasticNet(random_state=0,l1_ratio=0.7, alpha=0.001)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)\n",
    "\n",
    "#ENR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=10, nu=0.5) \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "    KRR_regr = KernelRidge(kernel='sigmoid', alpha=0.01,coef0=1)\n",
    "    KRR_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=KRR_regr.predict(x_data_training)\n",
    "    y_pred=KRR_regr.predict(x_data_test)\n",
    "      \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    Bay_Reg = linear_model.BayesianRidge(tol=0.00001)\n",
    "    Bay_Reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr =Bay_Reg.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_ = Bay_Reg.predict(x_data_test, return_std=True)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "    \n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[:],train[:])\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.scatter(train[:], stdPtr[:])\n",
    "plt.scatter(train[:], stdMtr[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()  \n",
    "\n",
    "plt.plot(test[:],test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.scatter(test[:], stdP[:])\n",
    "plt.scatter(test[:], stdM[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#BRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    regr = linear_model.ARDRegression(alpha_1=1e-08, alpha_2=1e-04,lambda_1=1e-04, lambda_2=1e-06)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr, std_tr =regr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=regr.predict(x_data_test,return_std=True)\n",
    "\n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "    \n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[:],train[:])\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.scatter(train[:], stdPtr[:])\n",
    "plt.scatter(train[:], stdMtr[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:],test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.scatter(test[:], stdP[:])\n",
    "plt.scatter(test[:], stdM[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)  \n",
    "\n",
    "#ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    forest_reg = RandomForestRegressor(max_features='sqrt', random_state=0, n_estimators=100, max_depth=10)\n",
    "    forest_reg.fit(x_data_training, y_data_training)\n",
    "    \n",
    "    y_pred_tr=forest_reg.predict(x_data_training)\n",
    "    y_pred=forest_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    Ada_regr = AdaBoostRegressor(random_state=0, loss='square',learning_rate=0.01, n_estimators=50)\n",
    "    Ada_regr.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=Ada_regr.predict(x_data_training)\n",
    "    y_pred=Ada_regr.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "\n",
    "#Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    gradientboost_reg = GradientBoostingRegressor(subsample=0.7, loss='lad',learning_rate=0.1, n_estimators=100, random_state=0)\n",
    "    gradientboost_reg.fit(x_data_training,y_data_training)\n",
    "    \n",
    "    y_pred_tr=gradientboost_reg.predict(x_data_training)\n",
    "    y_pred=gradientboost_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    xg_reg = xgb.XGBRegressor(subsample=0.4,learning_rate=0.1,max_depth=4,random_state=0)\n",
    "    xg_reg.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=xg_reg.predict(x_data_training)\n",
    "    y_pred=xg_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=1, nu=2.5) \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    svr_reg = SVR(kernel='linear', C=1)\n",
    "    svr_reg.fit(x_data_training, y_data_training)\n",
    "\n",
    "    y_pred_tr=svr_reg.predict(x_data_training)\n",
    "    y_pred=svr_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    knn_reg = KNeighborsRegressor(weights='distance',n_neighbors= 3,p=1)\n",
    "    knn_reg.fit(x_data_training, y_data_training)\n",
    "    \n",
    "    y_pred_tr=knn_reg.predict(x_data_training)\n",
    "    y_pred=knn_reg.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    regr = PLSRegression(n_components=1)\n",
    "    regr.fit(x_data_training,y_data_training)\n",
    "\n",
    "    y_pred_tr=regr.predict(x_data_training)\n",
    "    y_pred=regr.predict(x_data_test)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)    \n",
    "\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show() \n",
    "\n",
    "print(MSE_tr/91,MSE_te/91)\n",
    "\n",
    "#PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=10.0, nu=0.5) \n",
    "\n",
    "MSE_tr=0\n",
    "MSE_te=0\n",
    "train = []\n",
    "test = []\n",
    "train_p = []\n",
    "test_p = []\n",
    "stdP = []\n",
    "stdM = []\n",
    "stdPtr = []\n",
    "stdMtr = []\n",
    "\n",
    "xy = np.loadtxt('Input_data_path', delimiter=',', dtype=np.float32)\n",
    "xy_data=xy.reshape(-1,31)\n",
    "x_data = xy_data[:, :-2]\n",
    "y_data = xy_data[:, -2]\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x_data)\n",
    "\n",
    "for train_index, test_index in loo.split(x_data):\n",
    "    x_data_training, x_data_test = x_data[train_index], x_data[test_index]\n",
    "    y_data_training, y_data_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "    gpr = GaussianProcessRegressor(random_state=0,alpha=1e-10,  kernel= kernel)\n",
    "    gpr.fit(x_data_training, y_data_training)\n",
    "    \n",
    "    y_pred_tr, std_tr=gpr.predict(x_data_training, return_std=True)\n",
    "    y_pred, std_=gpr.predict(x_data_test, return_std=True)\n",
    "    \n",
    "    MSE_tr+=mean_squared_error(y_data_training, y_pred_tr, multioutput='uniform_average')\n",
    "    MSE_te+=mean_squared_error(y_data_test, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    train.append(y_data_training)\n",
    "    test.append(y_data_test)\n",
    "    train_p.append(y_pred_tr)\n",
    "    test_p.append(y_pred)\n",
    "    std_P_tr= y_pred_tr + std_tr\n",
    "    std_M_tr= y_pred_tr - std_tr\n",
    "    std_P = y_pred + std_\n",
    "    std_M = y_pred - std_\n",
    "    stdP.append(std_P)\n",
    "    stdM.append(std_M)\n",
    "    stdPtr.append(std_P_tr)\n",
    "    stdMtr.append(std_M_tr)\n",
    "    \n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.plot(train[:], train[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:], test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train[:],train[:])\n",
    "plt.scatter(train[:], train_p[:])\n",
    "plt.scatter(train[:], stdPtr[:])\n",
    "plt.scatter(train[:], stdMtr[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test[:],test[:])\n",
    "plt.scatter(test[:], test_p[:])\n",
    "plt.scatter(test[:], stdP[:])\n",
    "plt.scatter(test[:], stdM[:])\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.savefig('save_path', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(MSE_tr/91,MSE_te/91) \n",
    "\n",
    "#GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
